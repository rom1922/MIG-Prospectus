---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.17.3
kernelspec:
  name: python3
  display_name: Python 3 (ipykernel)
  language: python
---

+++ {"id": "at5zIeuVk6FI", "editable": true, "slideshow": {"slide_type": ""}}

# Machine Learning

Ce notebook propose une premi√®re exploration des m√©thodes de mod√©lisation appliqu√©es √† des donn√©es temporelles, afin d'illustrer comment le machine learning peut √™tre utilis√© pour estimer un facteur de charge √† partir de s√©ries chronologiques climatiques.

+++ {"id": "X10t3fiNYb8P"}

## G√©n√©ralit√©s

Les grandes √©tapes de la r√©alisation d'un mod√®le de machine learning :
1. Pr√©paration et Exploration
  *  Nettoyage et pr√©paration des donn√©es
  *  Exploration et analyse des donn√©es (EDA)
  *  Feature engineering
2. Mod√©lisation
  *  D√©coupage du jeu de donn√©es
  *  Choix du mod√®le
  *  Entra√Ænement et optimisation
3. √âvaluation et Interpr√©tation
  *  √âvaluation du mod√®le
  *  Interpr√©tation et validation m√©tier

Ici nous omettons les √©tapes de collecte des donn√©es (√©tape 0) et de mise en production du mod√®le (√©tape 4).

+++ {"id": "GFRj88TEn_uK"}

**Contexte :**

Nous disposons de donn√©es climatiques r√©gionales de temp√©rature et de pr√©cipitation pour la France continentale (21 r√©gions NUTS2) de 2015 √† 2023. Pour chaque ann√©e, nous disposons du **facteur de charge national** (NUTS0) des centrales hydro√©lectriques au fil de l‚Äôeau.

**Objectifs :** explorer les donn√©es, construire des variables explicatives simples et tester plusieurs mod√®les de r√©gression

+++ {"id": "wBQaWwFoqrl_"}

## 1. Pr√©paration et Exploration

+++ {"id": "XtGpEyd1V55f"}

### Nettoyage et pr√©paration des donn√©es

T√©l√©charger les donn√©es n√©cessaires pour l'analyse exploratoire. Les donn√©es sont d√©compress√©es dans le r√©pertoire `data`:
- `CF_1d.csv` : facteur de charge des centrales hydro√©lectriques au fil de l'eau au pas journalier de chaque pays europ√©en,
- `TA_1d.csv` : temp√©rature moyenne de l'air au pas journalier de chaque r√©gion administrative de chaque pays europ√©en,
- `TP_1d.csv` : cumul des pr√©cipitations au pas journalier de chaque r√©gion administrative de chaque pays europ√©en.

```{code-cell} ipython3
:id: QCGkj3VQVj1Z

!curl -sSL -q -o - "https://cloud.minesparis.psl.eu/index.php/s/MGp21fRa8LEzO3f/download?path=%2F&files=mig25_data.tgz" | tar -xzv
```

```{code-cell} ipython3
:id: F_ebaVmFHwMu

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib as mpl
import matplotlib.pyplot as plt

sns.set_style('whitegrid')
```

+++ {"id": "skjJZLvIaS1L"}

1. Charger les donn√©es dans des dataframes nomm√©s `cf`, `ta` et `tp` :

```{code-cell} ipython3
:id: Ym2zAg01-ANR

CF=pd.read_csv("data/CF_1d.csv")
TA=pd.read_csv("data/TA_1d.csv")
TP=pd.read_csv("data/TP_1d.csv")
print(CF.columns)
print(TA.columns)
print(TP.columns)
```

+++ {"id": "NxvjYl3baki6", "editable": true, "slideshow": {"slide_type": ""}}

2. Extraire les donn√©es en rapport avec la France continentale (21 r√©gions) pour chaque variable :

```{code-cell} ipython3
---
id: SheFL8ZR-Ca-
editable: true
slideshow:
  slide_type: ''
---
cf = CF[["Date", "FR"]].copy()   # üëà tr√®s important
# Colonnes de TA qui correspondent √† la France
fr_cols_ta = [col for col in TA.columns if "FR" in col]

# Colonnes de TP qui correspondent √† la France
fr_cols_tp = [col for col in TP.columns if "FR" in col]

# On garde Date + toutes les colonnes FR
ta = TA.loc[:, ["Date"] + fr_cols_ta]
tp = TP.loc[:, ["Date"] + fr_cols_tp]
ta = ta.set_index("Date")
tp = tp.set_index("Date")
cf = cf.set_index("Date")
```

+++ {"id": "F0OYV_TTEJfp"}

### Exploration et analyse des donn√©es

3. Afficher des informations de base sur les dataframes :

```{code-cell} ipython3
:id: 8w6C4seh98Hx

cf.info()
```

+++ {"id": "jM9FVVZnrMWD"}

4. a) Visualiser les donn√©es disponibles pour une r√©gion :

```{code-cell} ipython3
:id: ghLbqgJLA9vB

# 1) S'assurer que la date est au bon format
cf["Date"] = pd.to_datetime(cf["Date"])

# 2) Tracer l'√©volution du facteur de charge pour la France
plt.figure(figsize=(12, 4))
plt.plot(cf["Date"], cf["FR"])
plt.xlabel("Date")
plt.ylabel("Facteur de charge")
plt.title("√âvolution du facteur de charge - France")
plt.tight_layout()
plt.show()
```

+++ {"id": "ipN9MFk2aim4"}

4. b) Comment pourriez-vous organiser ces donn√©es pour comparer les profils journaliers d'une ann√©e √† l'autre ? Visualiser ces derniers sous forme de courbes et d'une heatmap.

```{code-cell} ipython3
:id: W9CxhcY-92qM

region = "FR10"  
TA["Date"] = pd.to_datetime(TA["Date"])
TP["Date"] = pd.to_datetime(TP["Date"])
TA["annee"] = TA["Date"].dt.year
TA["jour_annee"] = TA["Date"].dt.dayofyear
TP["annee"] = TP["Date"].dt.year
TP["jour_annee"] = TP["Date"].dt.dayofyear
tp_reg = TP[["annee", "jour_annee", region]].copy()

mat_TP = tp_reg.pivot(index="jour_annee", columns="annee", values=region)

plt.figure(figsize=(10, 6))
sns.heatmap(
    mat_TP,
    cmap="Blues",
    cbar_kws={"label": "Pr√©cipitations (mm)"}
)
plt.xlabel("Ann√©e")
plt.ylabel("Jour de l'ann√©e")
plt.title(f"Pr√©cipitations journali√®res - r√©gion {region}")
plt.tight_layout()
plt.show()
```

+++ {"id": "wIfT_MEOdFSo"}

4. c) Comment pourriez-vous r√©sumer statistiquement ces profils sur l‚Äôensemble des ann√©es pour chaque jour (quantiles, moyenne, etc) ?

```{code-cell} ipython3
:id: deV9HuXe9tMN

# 4.c) R√©sumer statistiquement les profils journaliers sur toutes les ann√©es
# ici pour la temp√©rature (mat_TA). M√™me id√©e pour mat_TP.

# Stats de base par jour (sur toutes les ann√©es)
stats_TP = pd.DataFrame({
    "moyenne": mat_TP.mean(axis=1),
    "mediane": mat_TP.median(axis=1),
    "minimum": mat_TP.min(axis=1),
    "maximum": mat_TP.max(axis=1),
    "ecart_type": mat_TP.std(axis=1),
})

# Quelques quantiles par jour
quantiles_TP = mat_TP.quantile([0.10, 0.25, 0.5, 0.75, 0.90], axis=1).T
quantiles_TP.columns = ["q10", "q25", "q50", "q75", "q90"]

# Tableau final : une ligne = un jour de l'ann√©e, colonnes = stats
stats_TP = pd.concat([stats_TP, quantiles_TP], axis=1)
stats_TP.head()
plt.figure(figsize=(12,5))
plt.plot(stats_TP.index, stats_TP["moyenne"], label="Moyenne")
plt.fill_between(
    stats_TP.index,
    stats_TP["q10"],
    stats_TP["q90"],
    alpha=0.3,
    label="[10%, 90%]"
)
plt.xlabel("Jour de l'ann√©e")
plt.ylabel("Temp√©rature")
plt.title("R√©sum√© statistique des profils journaliers (toutes ann√©es confondues)")
plt.legend()
plt.tight_layout()
plt.show()
```

+++ {"id": "loLbQfTKrhK7"}

### Feature engineering

L'√©tape pr√©liminaire dans le processus de d√©veloppement d'un mod√®le de machine learning est de construire ses variables de d√©cision pour qualifier ses observations. C'est une √©tape cl√© de l'ing√©nierie des donn√©es. Vous verrez que de mauvaises donn√©es (brutes, reconstruites ou compos√©es) ne conduisent √† aucun bon r√©sultat.

5. Construire un nouveau dataframe `data` de 3 colonnes : les temp√©ratures moyennes, le cumul moyen des pr√©cipitations et le facteur de charge :

```{code-cell} ipython3
:id: kGucUwQ0-T4S

# Colonnes de r√©gions fran√ßaises dans ta / tp
cols_fr_ta = [c for c in ta.columns if c.startswith("FR")]
cols_fr_tp = [c for c in tp.columns if c.startswith("FR")]

# Moyenne sur les r√©gions fran√ßaises (ligne par ligne)
temp_moy = ta[cols_fr_ta].mean(axis=1)
precip_moy = tp[cols_fr_tp].mean(axis=1)

# DataFrame final
data = pd.DataFrame({
    "T": temp_moy,
    "P": precip_moy,
    "CF": CF["FR"]
})
data.head()
```

+++ {"id": "OA-PX64ILCx-"}

## Mod√©lisation

Avant d'attaquer r√©ellement la mod√©lisation, il nous reste une derni√®re √©tape de traitement de donn√©es. Il nous faut d√©sormais s√©parer nos donn√©es en plusieurs jeux de donn√©es :

- un jeu d'entra√Ænement,
- un jeu de validation,
- un jeu de test.

Selon les mod√®les d'apprentissage que nous s√©lectionnerons, nous aurons besoin de standardiser/normaliser nos valeurs.

+++ {"id": "ln4MBjn5oDu9"}

### D√©coupage du jeu de donn√©es

6. a) S√©parer les variables de d√©cision et la cible en 2 variables `X` et `y`.  
   b) Cr√©er 2 jeux de donn√©es pour l'entrainement et le test  √† l'aide de de la fonction [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).  
   c) Standardiser les variables de d√©cision avec [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)

```{code-cell} ipython3
---
id: nH8CcojVtXuK
editable: true
slideshow:
  slide_type: ''
---
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# Features & Target
X = data.drop(columns="CF")
y = data["CF"]

# S√©paration des donn√©es d'entrainement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=365, shuffle=False)

# Normalisation
scaler = StandardScaler().set_output(transform="pandas")
X_train_std = scaler.fit_transform(X_train)
X_test_std = scaler.transform(X_test)

results = {"Actual": y_test}
```

+++ {"id": "vtcXr00KpRsI", "editable": true, "slideshow": {"slide_type": ""}}

### Choix du mod√®le

Nous en avons fini avec les donn√©es, tout est pr√™t pour mod√©liser notre probl√®me. Nous allons commencer avec des mod√®les simples de r√©gression. Pour nos premiers pas, nous utiliserons les mod√®les suivants :

* R√©gression lin√©aire : [`LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)
* R√©gression lin√©aire avec p√©nalit√© L1 [`Lasso`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)
* R√©gression lin√©aire avec p√©nalit√© L2 [`Ridge`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)
* Arbre de d√©cision : [`DecisionTreeRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)

Pour pousser plus loin, nous verrons √©galement les mod√®les suivants :
* For√™t al√©atoire : [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)
* Boosting de gradient : [`GradientBoostingRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html)

*Les √©tapes d'√©valuation et d'interpr√©tation de la 3√®me partie se feront en m√™me temps que la mod√©lisation et l'entrainement.*

```{code-cell} ipython3
:id: Ya_VGZXI2fmU

from sklearn.metrics import r2_score, mean_squared_error

def display_result(y_true, y_pred):
    """Affiche les r√©sultats de pr√©diction / r√©els."""
    fig = plt.figure(figsize=(16, 4), constrained_layout=True)
    gs = fig.add_gridspec(ncols=2, nrows=1, width_ratios=[2, 1])
    ax1 = fig.add_subplot(gs[0, 0])
    ax2 = fig.add_subplot(gs[0, 1])

    # Plot 1
    ax1.set_title("Capacity factor predictions")
    ax1.plot(y_true.index, y_true, color="tab:blue", label="Actual")
    ax1.plot(y_true.index, y_pred, color="tab:red", label="Predicted")

    ax1.set_xlim(y_true.index[0], y_true.index[-1])
    ax1.legend(loc="lower right", title="Capacity Factor")

    # Plot 2
    ax2.set_title("Actual vs Predicted")
    ax2.set_xlabel("Actual")
    ax2.set_ylabel("Predicted")
    ax2.scatter(y_true, y_pred, color="tab:blue", s=10)

    left, right = ax2.get_xlim()
    bottom, top = ax2.get_ylim()
    lb = min(left, bottom) - 0.01
    ub = max(right, top) + 0.01
    ax2.set_ylim(lb, ub)
    ax2.set_xlim(lb, ub)
    ax2.axline((lb, lb), (ub, ub), color="tab:red")

    plt.show()
```

+++ {"id": "IGiMnJThjKpt"}

#### 1. R√©gression lin√©aire

$$
\hat{\beta} = \arg\min_{\beta}
\left(
\sum_{i=1}^{n} (y_i - \mathbf{x}_i^\top \beta)^2
\right)
$$

Nous allons commencer par un mod√®le de r√©gression lin√©aire `LinearRegression`.

```{code-cell} ipython3
:id: iQdJy4dqLTpP

from sklearn.linear_model import LinearRegression

lr = LinearRegression()  # mod√®le de r√©gression lin√©aire
lr.fit(X_train, y_train)  # apprentissage supervis√©

y_pred = lr.predict(X_test)  # pr√©diction
y_pred = pd.Series(y_pred, index=y_test.index)
results["LinReg"] = y_pred

# M√©triques
r2 = r2_score(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)

# Param√®tres
w_ta, w_tp = lr.coef_
bias = lr.intercept_

print(f"R2: {r2:.06f}")
print(f"MSE: {mse:.06f}")
print(f"Weight[ta]: {w_ta:.6f}")
print(f"Weight[tp]: {w_tp:.6f}")
print(f"Bias: {bias:.6f}")
print()

display_result(y_test, y_pred)
```

+++ {"id": "wtpw1KZwhWoA"}

#### 2. R√©gression Lasso (L1)

$$
\hat{\beta} = \arg\min_{\beta}
\left(
\sum_{i=1}^{n} (y_i - \mathbf{x}_i^\top \beta)^2
\;+\;
\lambda \sum_{j=1}^{p} |\beta_j|
\right)
$$

Pour changer de mod√®le, c'est aussi simple que de changer son nom : de `LinearRegression` √† `Lasso`.

```{code-cell} ipython3
:id: CV8RyFHuYy-e

from sklearn.linear_model import Lasso

lasso = Lasso()  # mod√®le de r√©gression lin√©aire avec p√©nalit√© L1
lasso.fit(X_train, y_train)  # apprentissage supervis√©

y_pred = lasso.predict(X_test)  # pr√©diction
y_pred = pd.Series(y_pred, index=y_test.index)
results["Lasso"] = y_pred

# M√©triques
r2 = r2_score(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)

# Param√®tres
w_ta, w_tp = lasso.coef_
bias = lasso.intercept_

print(f"R2: {r2:.06f}")
print(f"MSE: {mse:.06f}")
print(f"Weight[ta]: {w_ta:.6f}")
print(f"Weight[tp]: {w_tp:.6f}")
print(f"Bias: {bias:.6f}")
print()

display_result(y_test, y_pred)
```

+++ {"id": "DdSnwXmUJMr8"}

7. Observez les pr√©dictions r√©alisez ? Pourquoi un tel comportement et d'o√π provient ce r√©sultat.

+++ {"id": "awB5EcxriOAE"}

#### R√©gression Ridge (L2)

$$
\hat{\beta} = \arg\min_{\beta}
\left(
\sum_{i=1}^{n} (y_i - \mathbf{x}_i^\top \beta)^2
\;+\;
\lambda \sum_{j=1}^{p} \beta_j^2
\right)
$$

Vous l'aurez compris pour faire un mod√®le `Ridge`, il suffit d'instancier le mod√®le du m√™me nom. Ici nous allons observer 2 comportement diff√©rents selon les donn√©es pass√©es √† l'entrainement : donn√©es brutes ou donn√©es standardis√©es.

+++ {"id": "hJn1D-_XjAts"}

**A. Sur donn√©es brutes :**

```{code-cell} ipython3
:id: N8W9JcRT756X

# votre code ici

from sklearn.linear_model import Ridge
ridge=Ridge(alpha=1000)
ridge.fit(X_train,y_train)
y_pred=ridge.predict(X_test)
r2=r2_score(y_test,y_pred)
mse=mean_squared_error(y_test,y_pred)
wt,wp= ridge.coef_
b=ridge.intercept_

print(f"R2:{r2:.06f}")
print(f"MSE:{mse:.06f}")
print(f"Wt:{wt:.06f}")
print(f"Wp:{wp:.06f}")
display_result(y_test,y_pred)
```

+++ {"id": "JKtmLIdfix8S"}

**B. Sur donn√©es standardis√©es :**

```{code-cell} ipython3
:id: lwBxWl4O78ev

# votre code ici

from sklearn.linear_model import Ridge
ridge=Ridge(alpha=0.8)
ridge.fit(X_train_std,y_train)
y_pred=ridge.predict(X_test_std)
r2=r2_score(y_test,y_pred)
mse=mean_squared_error(y_test,y_pred)
wt,wp= ridge.coef_
b=ridge.intercept_

print(f"R2:{r2:.06f}")
print(f"MSE:{mse:.06f}")
print(f"Wt:{wt:.06f}")
print(f"Wp:{wp:.06f}")
display_result(y_test,y_pred)
```

+++ {"id": "tGIXhOgiJBpz"}

8. Observez les pr√©dictions r√©alis√©es. Que remarquez vous ?

+++ {"id": "N8gjR0PwA7iS"}

#### Arbre de d√©cision

M√™me si nous changeons de type de mod√®le, la m√©thodologie reste la m√™me. Par contre, il est √©vident que les param√®tres du mod√®le ne seront plus les m√™mes (poids et biais pour la r√©gression lin√©aire vs variables, seuils et valeurs de pr√©diction pour l'arbre de d√©cision)

```{code-cell} ipython3
:id: R9kS4Bw8ZCN6

#¬†votre code ici

from sklearn.tree import DecisionTreeRegressor
dt = DecisionTreeRegressor(
    max_depth=3,          # profondeur maximale
     min_samples_leaf=200,  # nb minimal d'exemples par feuille
    random_state=0
)
dt.fit(X_train,y_train)
y_pred=dt.predict(X_test)
r2=r2_score(y_test,y_pred)
mse=mean_squared_error(y_test,y_pred)
display_result(y_test,y_pred)
print(f"R2:{r2:.06f}")
print(f"MSE:{mse:.06f}")
```

+++ {"id": "nEadHXHvZYbw"}

Nous pouvons visualiser sous forme de table les diff√©rents param√®tres du mod√®le :

```{code-cell} ipython3
:id: CB6cWH9nBxwk

dmap = dict(enumerate(X.columns)) | {-2: "Leave"}
params = {"Feature": dt.tree_.feature,
          "Threshold": dt.tree_.threshold,
          "Value": dt.tree_.value.squeeze()}

params = pd.DataFrame(params).replace({"Feature": dmap})
params
```

+++ {"id": "ny_G5Nr9Zxr0"}

Il est m√™me possible de visualiser facilement l'arbre de d√©cision :

```{code-cell} ipython3
---
id: 51v_uhE-IDgr
editable: true
slideshow:
  slide_type: ''
---
from sklearn.tree import plot_tree

fig, ax = plt.subplots(figsize=(18, 9))
plot_tree(dt, feature_names=X.columns, filled=True, fontsize=10, max_depth=3, ax=ax)
plt.show()
```

+++ {"id": "dAvKuso1LnSg"}

#### Recherche par grille

Jusqu'√† pr√©sent, nous avons utilis√© nos 4 mod√®les sans configurer quoi ce soit :

```
lr = LinearRegression()
lasso = Lasso()
ridge = Ridge()
dt = DecisionTreeRegressor()
```

Cela manque de souplesse n'est ce pas ? Comment r√©gler correctement le coefficient de p√©nalit√© dans mes r√©gressions ou d√©finir la profondeur optimale de mon arbre de d√©cision ? Il s'agit donc pour nous de configurer les meilleurs hyperparam√®tres du mod√®le afin de contr√¥ler son apprentissage.

Pour cela nous utiliserons une recherche par grille : [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)

> **Note** : il ne faut pas confondre les param√®tres d'une fonction (ou plu√¥t ses arguments) qui sont les hyperparam√®tres du mod√®le avec les param√®tres du mod√®le qui sont les variables internes permettant de sortir une pr√©diction apr√®s apprentissage.

```{code-cell} ipython3
:id: ji1BzCNoIXdb

from sklearn.model_selection import GridSearchCV

params = {
    "max_depth": np.arange(1, 10),
}
reg = DecisionTreeRegressor(random_state=2024)  # mod√®le d'arbre de d√©cision
cv = GridSearchCV(reg, param_grid=params)  # recherche par grille
cv.fit(X_train, y_train)  # apprentissage supervis√©

y_pred = cv.predict(X_test)  # pr√©diction
yc_pred = pd.Series(y_pred, index=y_test.index)
results["DTCV"] = yc_pred

# M√©triques
r2 = r2_score(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)

print(f"R2: {r2:.06f}")
print(f"MSE: {mse:.06f}")

display_result(y_test, y_pred)
cv.best_estimator_
```

```{code-cell} ipython3
:id: 5BepN2qqLvkk

pd.DataFrame(cv.cv_results_)
```

```{code-cell} ipython3
:id: NExTlFMUi7Y1

from sklearn.tree import plot_tree

fig, ax = plt.subplots(figsize=(18, 9))
plot_tree(cv.best_estimator_, feature_names=X.columns, filled=True, fontsize=10, max_depth=3, ax=ax)
plt.show()
```

+++ {"id": "EW4S_YYxoGeH"}

### Evaluation et Interpr√©tation

Nous avons constat√© que nos mod√®les ne sont pas bons mais nous n'avons pas pu les visualiser simultan√©ment sur un m√™me graphique.

```{code-cell} ipython3
:id: a87_yXZWodXP

dfr = pd.DataFrame(results)
dfr
```

```{code-cell} ipython3
:id: cHKnLk89o83b

fig, axs = plt.subplots(ncols=2, nrows=3, figsize=(15, 9), sharex=True, sharey=True, constrained_layout=True)

for ax, col in zip(axs.flatten(), dfr.columns[1:]):
  dfr[col].plot(ax=ax, lw=0.8, color="tab:red", title=col)
  dfr["Actual"].plot(ax=ax, lw=0.8, color="tab:blue")
plt.show()
```

+++ {"id": "F2S_rzAlV46g"}

# Et maintenant ?

Nous avons vu que nos simples variables ne sont pas suffisantes pour r√©aliser un mod√®le performant. Toutefois cela nous a permis de d√©velopper rapidement un premier mod√®le d'apprentissage automatique.

D√©sormais, il va nous falloir cr√©er des variables explicatives plus en ad√©quation avec le probl√®me que nous tentons de mod√©liser.

Sans √™tre hydrologue ou m√©t√©orologue, il est n√©cessaire de comprendre un minimum les ph√©nom√®nes physiques li√©s au cycle de l'eau :

![Cycle de l'eau](https://geotechniquehse.com/wp-content/uploads/2024/10/hydrogeologie-cycle-de-leau.png)

9. **Que proposeriez vous comme nouvelles variables explicatives ?**

**La r√©ponse a cette question passe par l'√©tude de la corr√©lation spatiale et temporelle qui lie les variables climatiques au facteur de charge.**

Quand vous aurez des variables en ad√©quation avec votre probl√®me, vous pourrez utiliser des mod√®les plus performants comme les for√™ts al√©atoire et le boosting de gradient, voire des r√©seaux de neurones.

+++ {"id": "cLVIUYbZBViO"}

# Informations (tr√®s) utiles

+++ {"id": "pMuH44LCBpS6"}

## M√©thodes d'encodage des donn√©es pour l'apprentissage

Tout au long du processus de cr√©ation des variables, il arrivera que nous devions les mettre sous une autre forme. Voici quelques une des principales transformations :

1. [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)  
   **Objectif :** Transformer des variables cat√©gorielles en une forme que les mod√®les peuvent comprendre en cr√©ant une colonne binaire pour chaque cat√©gorie.  
   **A utiliser :**
   - pour les variables **nominales** (sans ordre ou relation entre les cat√©gories).
   - lorsqu'il y a des cat√©gories discr√®tes et qu'il est n√©cessaire de les traiter ind√©pendamment.

2. [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)  
   **Objectif :** Standardiser les donn√©es num√©riques de mani√®re √† ce qu‚Äôelles soient centr√©es autour de leur moyenne et comparables par leur √©cart-type. Cela permet de traiter des variables avec diff√©rentes √©chelles.  
   **A utiliser :**
   - pour les mod√®les sensibles √† l'√©chelle des donn√©es, tels que les r√©gressions lin√©aires, les SVM, ou les r√©seaux de neurones.
   - lorsque les donn√©es ont des unit√©s diff√©rentes ou des amplitudes diff√©rentes.

3. [`MinMaxScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)  
   **Objectif :** Mettre √† l'√©chelle les donn√©es entre une plage sp√©cifi√©e, g√©n√©ralement entre 0 et 1.  
   **A utiliser :**
   - lorsqu'il est n√©cessaire que les donn√©es soient dans un intervalle sp√©cifique, surtout pour les mod√®les sensibles √† l'√©chelle (comme les r√©seaux de neurones, o√π l'activation se fait souvent sur des valeurs entre 0 et 1).
   - lorsque les donn√©es doivent √™tre dans un certain intervalle.

4. Cyclical Features Encoding  
   **Objectif :** Capturer la relation cyclique des donn√©es saisonni√®res en les transformant sur un cercle unitaire avec les fonctions trigonom√©triques `sin` et `cos`.  
   **A utiliser :**
     - pour des donn√©es cycliques.
     - lorsqu'il est n√©cessaire de pr√©server l'ordre temporel et la continuit√©.

+++ {"id": "o8v9CrbxEp3Q"}

## M√©thodes de d√©coupage des donn√©es pour la validation crois√©e

La cr√©ation de jeux de donn√©es de s√©ries temporelles dans le cadre de pr√©vision se fait rarement de mani√®re al√©atoire. Cela peut entra√Æner des probl√®mes de g√©n√©ralisation et ne repr√©sente pas le cas d'usage principal.

1. **[`TimeSeriesSplit`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html) : D√©coupage temporel s√©quentiel**  
   - Convient pour les s√©ries temporelles o√π l'ordre chronologique est crucial.  
   - Les donn√©es sont d√©coup√©es de mani√®re progressive : chaque split utilise une portion plus grande des donn√©es pass√©es pour l'entra√Ænement, et les donn√©es futures pour le test.  
   - Les indices sont respect√©s pour ne pas m√©langer les informations futures dans l'entra√Ænement.  
   - Exemple :
     - Split 1 : Train = [2015], Test = [2016]  
     - Split 2 : Train = [2015, 2016], Test = [2017]  
     - Split 3 : Train = [2015, 2016, 2017], Test = [2018].

2. **[`GroupKFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html) : D√©coupage par groupes (par exemple, ann√©es)**  
   - Permet de s'assurer que les groupes (comme les ann√©es ou d'autres identifiants logiques) ne sont jamais m√©lang√©s entre l'entra√Ænement et le test.  
   - Chaque split utilise des groupes diff√©rents pour l'entra√Ænement et le test.  
   - Utile lorsque les donn√©es doivent rester group√©es par identifiant logique.  
   - Exemple :
     - Split 1 : Train = [2016, 2017, 2018], Test = [2015]  
     - Split 2 : Train = [2015, 2017, 2018], Test = [2016]  
     - Split 3 : Train = [2015, 2016, 2018], Test = [2017].
     - Split 4 : Train = [2015, 2016, 2017], Test = [2018].

> **Note :** Ces deux m√©thodes peuvent √™tre directement utilis√©es comme param√®tre de [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) pour optimiser les hyperparam√®tres tout en respectant les sp√©cificit√©s des donn√©es.

```{code-cell} ipython3
#pr√©paration de DATA
ta.index = pd.to_datetime(ta.index)
tp.index = pd.to_datetime(tp.index)
cf.index = pd.to_datetime(cf.index)
df = cf.join([ta.add_prefix("T_"), tp.add_prefix("P_")], how="inner")
df = df.rename(columns={"FR": "CF"})
hydro_strong = ["FRK2","FRL0","FRI2","FRJ2","FRK1","FRG0","FRJ1","FRI1"]  # Alpes, Pyr√©n√©es, Massif Central, Jura
hydro_medium = ["FRF1","FRF3","FRH0","FRB0","FRC1","FRC2"]               # Vosges, Morvan, etc.
hydro_weak   = ["FR10","FRE1","FRE2","FRD1","FRD2","FRF2","FRI3"]        # grandes plaines nord / ouest
def add_season_features(df):
    dayofyear = df.index.dayofyear
    df["day_sin"] = np.sin(2 * np.pi * dayofyear / 365)
    df["day_cos"] = np.cos(2 * np.pi * dayofyear / 365)
    return df

def add_cf_lags(df, lags=[1, 7, 30]):
    for L in lags:
        df[f"CF_lag{L}"] = df["CF"].shift(L)
    return df

def rolling_sum(df, cols, window, min_periods=None, suffix=""):
    if min_periods is None:
        min_periods = window // 3
    for c in cols:
        df[f"{c}_sum{window}{suffix}"] = df[c].rolling(window, min_periods=min_periods).sum()
    return df

def rolling_mean(df, cols, window, min_periods=None, suffix=""):
    if min_periods is None:
        min_periods = window // 3
    for c in cols:
        df[f"{c}_mean{window}{suffix}"] = df[c].rolling(window, min_periods=min_periods).mean()
    return df
```

```{code-cell} ipython3
#Exp√©rience 1
df1 = df.copy()
T_cols = [c for c in df1.columns if c.startswith("T_")]
P_cols = [c for c in df1.columns if c.startswith("P_")]

df1["T_nat"] = df1[T_cols].mean(axis=1)
df1["P_nat"] = df1[P_cols].mean(axis=1)

df1 = add_season_features(df1)
df1 = add_cf_lags(df1, lags=[1, 7, 30])

df1["P_nat_sum7"]   = df1["P_nat"].rolling(7,  min_periods=3).sum()
df1["P_nat_sum30"]  = df1["P_nat"].rolling(30, min_periods=10).sum()
df1["P_nat_sum90"]  = df1["P_nat"].rolling(90, min_periods=30).sum()
df1["T_nat_mean7"]  = df1["T_nat"].rolling(7,  min_periods=3).mean()
df1["T_nat_mean30"] = df1["T_nat"].rolling(30, min_periods=10).mean()

feature_cols_1 = [
    "T_nat","P_nat",
    "T_nat_mean7","T_nat_mean30",
    "P_nat_sum7","P_nat_sum30","P_nat_sum90",
    "day_sin","day_cos",
    "CF_lag1","CF_lag7","CF_lag30"
]

data1 = df1[feature_cols_1 + ["CF"]].dropna()
X1 = data1[feature_cols_1]
y1 = data1["CF"]
```

```{code-cell} ipython3
#Exp√©rience 2
df2 = df.copy()

# 1) Moyennes par groupe
df2["T_hydro_strong"] = df2[[f"T_{r}" for r in hydro_strong]].mean(axis=1)
df2["P_hydro_strong"] = df2[[f"P_{r}" for r in hydro_strong]].mean(axis=1)

df2["T_hydro_medium"] = df2[[f"T_{r}" for r in hydro_medium]].mean(axis=1)
df2["P_hydro_medium"] = df2[[f"P_{r}" for r in hydro_medium]].mean(axis=1)

df2["T_hydro_weak"] = df2[[f"T_{r}" for r in hydro_weak]].mean(axis=1)
df2["P_hydro_weak"] = df2[[f"P_{r}" for r in hydro_weak]].mean(axis=1)

# 2) Rolling sur ces colonnes
for col in ["P_hydro_strong","P_hydro_medium","P_hydro_weak"]:
    df2[f"{col}_sum30"] = df2[col].rolling(30, min_periods=10).sum()
    df2[f"{col}_sum90"] = df2[col].rolling(90, min_periods=30).sum()

for col in ["T_hydro_strong","T_hydro_medium","T_hydro_weak"]:
    df2[f"{col}_mean7"] = df2[col].rolling(7, min_periods=3).mean()

# 3) Saison + lags CF
df2 = add_season_features(df2)
df2 = add_cf_lags(df2, lags=[1,7,30])

feature_cols_2 = [
    "T_hydro_strong","T_hydro_medium","T_hydro_weak",
    "P_hydro_strong","P_hydro_medium","P_hydro_weak",
    "P_hydro_strong_sum30","P_hydro_strong_sum90",
    "P_hydro_medium_sum30","P_hydro_medium_sum90",
    "P_hydro_weak_sum30","P_hydro_weak_sum90",
    "T_hydro_strong_mean7","T_hydro_medium_mean7","T_hydro_weak_mean7",
    "day_sin","day_cos",
    "CF_lag1","CF_lag7","CF_lag30"
]

data2 = df2[feature_cols_2 + ["CF"]].dropna()
X2 = data2[feature_cols_2]
y2 = data2["CF"]
```

```{code-cell} ipython3
#Exp√©rience 3
df_corr = df.copy()

# Ex : cumul de pluie sur 90 jours pour chaque r√©gion
P_cols = [c for c in df_corr.columns if c.startswith("P_")]
for c in P_cols:
    df_corr[f"{c}_sum90"] = df_corr[c].rolling(90, min_periods=30).sum()

# Corr√©lation avec CF
corrs = {}
for c in P_cols:
    corrs[c] = df_corr[f"{c}_sum90"].corr(df_corr["CF"])

# Top 5 en valeur absolue
top_regions = sorted(corrs, key=lambda k: abs(corrs[k]), reverse=True)[:5]
top_regions = [c.replace("P_","") for c in top_regions]  # remettre le code r√©gion pur

print("Top r√©gions m√©t√©o corr√©l√©es au CF :", top_regions)

df3 = df.copy()

for r in top_regions:
    df3[f"P_{r}_sum30"] = df3[f"P_{r}"].rolling(30, min_periods=10).sum()
    df3[f"P_{r}_sum90"] = df3[f"P_{r}"].rolling(90, min_periods=30).sum()
    df3[f"T_{r}_mean7"] = df3[f"T_{r}"].rolling(7,  min_periods=3).mean()

df3 = add_season_features(df3)
df3 = add_cf_lags(df3, lags=[1,7,30])

feature_cols_3 = []
for r in top_regions:
    feature_cols_3 += [f"P_{r}_sum30", f"P_{r}_sum90", f"T_{r}_mean7"]

feature_cols_3 += ["day_sin","day_cos","CF_lag1","CF_lag7","CF_lag30"]

data3 = df3[feature_cols_3 + ["CF"]].dropna()
X3 = data3[feature_cols_3]
y3 = data3["CF"]
```

```{code-cell} ipython3
#Exp√©rience 4
df4 = df.copy()

for r in hydro_strong:
    df4[f"P_{r}_sum30"] = df4[f"P_{r}"].rolling(30, min_periods=10).sum()
    df4[f"P_{r}_sum90"] = df4[f"P_{r}"].rolling(90, min_periods=30).sum()
    df4[f"T_{r}_mean7"] = df4[f"T_{r}"].rolling(7,  min_periods=3).mean()

df4 = add_season_features(df4)
df4 = add_cf_lags(df4, lags=[1,7,30])

feature_cols_4 = []
for r in hydro_strong:
    feature_cols_4 += [f"P_{r}_sum30", f"P_{r}_sum90", f"T_{r}_mean7"]

feature_cols_4 += ["day_sin","day_cos","CF_lag1","CF_lag7","CF_lag30"]

data4 = df4[feature_cols_4 + ["CF"]].dropna()
X4 = data4[feature_cols_4]
y4 = data4["CF"]
```

```{code-cell} ipython3
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV, TimeSeriesSplit
from sklearn.metrics import r2_score, mean_squared_error
import numpy as np

def run_rf_experiment(df, feature_cols, param_grid, name="exp"):
    """
    df           : DataFrame complet (index = Date, colonne cible = 'CF')
    feature_cols : liste des colonnes X √† utiliser pour cette exp√©rience
    param_grid   : dict d'hyperparam√®tres pour GridSearchCV
    name         : nom de l'exp√©rience (juste pour l'affichage)
    """

    # --- 1. D√©coupage Train / Test : on garde les 365 derniers jours pour le test
    train = df.iloc[:-365].copy()
    test  = df.iloc[-365:].copy()

    X_train = train[feature_cols]
    y_train = train["CF"]

    X_test  = test[feature_cols]
    y_test  = test["CF"]

    # --- 2. Mod√®le de base
    rf_base = RandomForestRegressor(
        bootstrap=True,      # tu voulais le garder √† True
        random_state=2024,
        n_jobs=-1            # utilise tous les c≈ìurs dispo
    )

    # TimeSeriesSplit pour respecter le temps dans la CV
    tscv = TimeSeriesSplit(n_splits=5)

    grid = GridSearchCV(
        rf_base,
        param_grid=param_grid,
        cv=tscv,
        scoring="r2",
        n_jobs=-1
    )

    # --- 3. Entra√Ænement + recherche d‚Äôhyperparam√®tres sur le TRAIN
    grid.fit(X_train, y_train)

    best_rf = grid.best_estimator_

    print(f"\n===== {name} =====")
    print("Meilleurs hyperparam√®tres :", grid.best_params_)
    print(f"R2 moyen en CV : {grid.best_score_:.3f}")

    # --- 4. √âvaluation sur le TEST (les 365 derniers jours)
    y_pred = best_rf.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    print(f"R2 sur test : {r2:.3f}")
    print(f"MSE sur test : {mse:.6f}")

    # Si tu as d√©j√† la fonction du cours :
    try:
        display_result(y_test, y_pred)
    except NameError:
        pass  # si display_result n'existe pas dans ton notebook

    return best_rf, y_test, y_pred
param_grid_exp1 = {
    "n_estimators": [100, 300, 600],
    "max_depth": [3, 5, 7, None],
    "min_samples_leaf": [1, 3, 5]
}
# Exp√©rience 1
best_rf1, y_test1, y_pred1 = run_rf_experiment(
    df,
    feature_cols=features_exp1,
    param_grid=param_grid_exp1,
    name="Exp√©rience 1 - features simples"
)

# Exp√©rience 2 (autre grille si tu veux)
param_grid_exp2 = {
    "n_estimators": [100, 300, 800],
    "max_depth": [5, 10, None],
    "min_samples_leaf": [1, 2, 4]
}

best_rf2, y_test2, y_pred2 = run_rf_experiment(
    df,
    feature_cols=features_exp2,
    param_grid=param_grid_exp2,
    name="Exp√©rience 2 - moyennes & cumuls"
)
```

```{code-cell} ipython3
#Impl√©mentation du mod√®le
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV
params={"n_estimators":np.arange(50,300,50),"max_depth":np.arange(1,6)}
RF=RandomForestRegressor(n_estimators=1000,max_depth=3,bootstrap=True,random_state=2024,n_jobs=6)
#cv=GridSearchCV(RF,param_grid=params)
RF.fit(X_train,y_train)
y_pred=RF.predict(X_test)
r2=r2_score(y_test,y_pred)
print(f"R2:{r2:.06f}")
display_result(y_test,y_pred)
```
