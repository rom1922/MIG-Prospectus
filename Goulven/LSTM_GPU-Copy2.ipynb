{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3f90006-b457-49fa-8c56-936a90ee0c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04ec70c5-20f2-4d16-94ef-9387a03264f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_result_season(y_true, y_pred, index):\n",
    "    \"\"\"\n",
    "    Fonction fournie par l'utilisateur pour la visualisation saisonnière.\n",
    "    y_true : Pandas Series avec DatetimeIndex\n",
    "    y_pred : Array numpy ou Pandas Series (valeurs prédites)\n",
    "    \"\"\"\n",
    "    dmap = {\n",
    "        12: 'DJF', 1: 'DJF', 2: 'DJF',\n",
    "        3: 'MAM', 4: 'MAM', 5: 'MAM',\n",
    "        6: 'JJA', 7: 'JJA', 8: 'JJA',\n",
    "        9: 'SON', 10: 'SON', 11: 'SON'\n",
    "    }\n",
    "    cmap = {\"DJF\": \"tab:blue\", \"MAM\": \"tab:green\",\n",
    "            \"JJA\": \"tab:red\", \"SON\": \"tab:orange\"}\n",
    "    \n",
    "    # Vérification et mappage des saisons\n",
    "    seasons = index.month.map(dmap)\n",
    "    colors = seasons.map(cmap)\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 4), constrained_layout=True)\n",
    "    gs = fig.add_gridspec(ncols=2, nrows=1, width_ratios=[2, 1])\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "    # Plot 1 : Séries Temporelles\n",
    "    ax1.set_title(\"Capacity factor predictions\")\n",
    "    ax1.plot(index, y_true, color=\"tab:blue\", label=\"Actual\")\n",
    "    ax1.plot(index, y_pred, color=\"tab:red\", label=\"Predicted\")\n",
    "    ax1.set_xlim(index[0], index[-1])\n",
    "    ax1.legend(loc=\"lower right\", title=\"Capacity Factor\")\n",
    "\n",
    "    # Plot 2 : Scatter Plot (Actual vs Predicted)\n",
    "    ax2.set_title(\"Actual vs Predicted\")\n",
    "    ax2.set_xlabel(\"Actual\")\n",
    "    ax2.set_ylabel(\"Predicted\")\n",
    "    ax2.scatter(y_true, y_pred, c=colors, s=10)\n",
    "\n",
    "    # Diagonale idéale (y=x)\n",
    "    left, right = ax2.get_xlim()\n",
    "    bottom, top = ax2.get_ylim()\n",
    "    lb = min(left, bottom) - 0.01\n",
    "    ub = max(right, top) + 0.01\n",
    "    ax2.set_xlim(lb, ub)\n",
    "    ax2.set_ylim(lb, ub)\n",
    "    ax2.axline((lb, lb), (ub, ub), color=\"tab:red\")\n",
    "\n",
    "    # Légende des saisons\n",
    "    handles = [\n",
    "        plt.Line2D([0], [0], marker='o', color='w', label=s, \n",
    "                   markerfacecolor=cmap[s], markersize=6)\n",
    "        for s in [\"DJF\", \"MAM\", \"JJA\", \"SON\"]\n",
    "    ]\n",
    "    ax2.legend(handles=handles, title=\"Season\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a41058ac-f772-4079-a156-80644689a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = pd.read_csv(\"data/CF_1d.csv\", index_col=\"Date\", parse_dates=[\"Date\"])\n",
    "ta = pd.read_csv(\"data/TA_1d.csv\", index_col=\"Date\", parse_dates=[\"Date\"])\n",
    "tp = pd.read_csv(\"data/TP_1d.csv\", index_col=\"Date\", parse_dates=[\"Date\"])\n",
    "\n",
    "cf = cf[[\"FR\"]]\n",
    "ta = ta.loc[:, ta.columns.str.startswith(\"FR\")]\n",
    "tp = tp.loc[:, tp.columns.str.startswith(\"FR\")]\n",
    "\n",
    "data = pd.concat([ta.mean(axis=1).rename(\"TA\"),\n",
    "                  tp.mean(axis=1).rename(\"TP\"),\n",
    "                  cf[\"FR\"].rename(\"CF\")], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7c31f80-03e6-4367-aab8-e2c0593e781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. Configuration Globale (Hyperparamètres)\n",
    "# ==========================================\n",
    "class Config:\n",
    "    # Fenêtres physiques (Feature Engineering)\n",
    "    WINDOW_TP = 7    # Jours pour l'accumulation de pluie\n",
    "    WINDOW_TA = 30   # Jours pour l'inertie thermique\n",
    "    \n",
    "    # Fenêtres du Modèle (Architecture LSTM)\n",
    "    SEQ_LENGTH = 90  # Look-back window (Profondeur BTT)\n",
    "    PRED_HORIZON = 1 # Prédiction à t+1\n",
    "    \n",
    "    # Architecture\n",
    "    HIDDEN_SIZE = 64\n",
    "    NUM_LAYERS = 3\n",
    "    DROPOUT = 0.2\n",
    "    BATCH_SIZE = 32\n",
    "    \n",
    "    # Entraînement\n",
    "    LR = 0.001\n",
    "    EPOCHS = 100\n",
    "    DROPOUT = 0.2\n",
    "\n",
    "CONFIG = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "668ef293-b3b4-4ae1-9322-d4e2ed1690fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choisir une machine\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cd96b43-af0f-4c6b-956e-f2794ad050ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. Préparation des données\n",
    "# ==========================================\n",
    "X1 = data.drop(columns=\"CF\")\n",
    "yn = data[\"CF\"]\n",
    "\n",
    "#ajout d'une feunêtre\n",
    "X_days_TP = X1[\"TP\"].rolling(window=CONFIG.WINDOW_TP, min_periods=1).sum()\n",
    "X_days_TA = X1[\"TA\"].rolling(window=CONFIG.WINDOW_TA, min_periods=1).mean()\n",
    "X_days_TP = X_days_TP.reset_index(drop=True)\n",
    "X_days_TA = X_days_TA.reset_index(drop=True)\n",
    "\n",
    "#Création du tableau\n",
    "Xn = pd.concat([X_days_TP, X_days_TA], axis = 1)\n",
    "\n",
    "#Création des séries temporelles\n",
    "Xt = []\n",
    "yt = []\n",
    "for i in range(len(Xn)-CONFIG.SEQ_LENGTH):\n",
    "    Xt.append(Xn.iloc[i:i+CONFIG.SEQ_LENGTH])\n",
    "    yt.append(yn.iloc[i+CONFIG.SEQ_LENGTH])\n",
    "Xt =  np.array(Xt)\n",
    "yt = np.array(yt)\n",
    "\n",
    "#Dataset\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n",
    "ds = TimeSeriesDataset(Xt, yt)\n",
    "#Mise en GPU (la puissance)\n",
    "ds.X = ds.X.to(device)\n",
    "ds.y = ds.y.to(device)\n",
    "\n",
    "#création des sous dataset\n",
    "\n",
    "total_len = len(ds)\n",
    "test_len = 365\n",
    "split_idx = total_len - test_len\n",
    "\n",
    "train_indices = range(0, split_idx)\n",
    "test_indices = range(split_idx, total_len)\n",
    "\n",
    "train_ds = Subset(ds, train_indices)\n",
    "test_ds = Subset(ds, test_indices)\n",
    "\n",
    "# Gestionnaire de batchs\n",
    "train_loader = DataLoader(train_ds, batch_size=CONFIG.BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=CONFIG.BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b849849-37d6-4b8a-bfe5-e8b12dc5d12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. Le modèle de deep learning\n",
    "# ==========================================\n",
    "torch.set_num_threads(10)\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.2):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Couche LSTM\n",
    "        # input_shape attendu : (batch_size, sequence_length, input_size)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers, \n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # Couche entièrement connectée pour la régression finale\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialisation des états cachés (h_0, c_0)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Propagation avant (Forward pass)\n",
    "        # out shape: (batch_size, seq_length, hidden_size)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # On récupère seulement la sortie du dernier pas de temps de la séquence\n",
    "        # out[:, -1, :] shape: (batch_size, hidden_size)\n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        # Prédiction finale\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "584a2e85-a6e7-4081-9ed7-9b8165f840fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début de l'entraînement...\n",
      "Epoch [10/100], Train Loss: 0.0076, Test Loss: 0.0052\n",
      "Epoch [20/100], Train Loss: 0.0060, Test Loss: 0.0024\n",
      "Epoch [30/100], Train Loss: 0.0089, Test Loss: 0.0028\n",
      "Epoch [40/100], Train Loss: 0.0047, Test Loss: 0.0026\n",
      "Epoch [50/100], Train Loss: 0.0043, Test Loss: 0.0027\n",
      "Epoch [60/100], Train Loss: 0.0035, Test Loss: 0.0027\n",
      "Epoch [70/100], Train Loss: 0.0030, Test Loss: 0.0030\n",
      "Epoch [80/100], Train Loss: 0.0031, Test Loss: 0.0033\n",
      "Epoch [90/100], Train Loss: 0.0028, Test Loss: 0.0035\n",
      "Epoch [100/100], Train Loss: 0.0023, Test Loss: 0.0032\n",
      "Entraînement terminé.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 4. Entrainement\n",
    "# ==========================================\n",
    "#torch.manual_seed(42)\n",
    "torch.set_num_threads(10)\n",
    "\n",
    "input_dim = len(X1.columns)\n",
    "model = LSTM(\n",
    "    input_size=input_dim, \n",
    "    hidden_size=CONFIG.HIDDEN_SIZE, \n",
    "    num_layers=CONFIG.NUM_LAYERS, \n",
    "    output_size=1,\n",
    "    dropout=CONFIG.DROPOUT\n",
    ").to(device)\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = Adam(params=model.parameters(), lr=CONFIG.LR)\n",
    "\n",
    "# Paramètres pour la normalisation\n",
    "Xstd, *_ = train_ds.dataset[train_ds.indices]\n",
    "mu, sigma = Xstd.mean(dim=0), Xstd.std(dim=0)\n",
    "\n",
    "train_history = []\n",
    "\n",
    "print(\"Début de l'entraînement...\")\n",
    "for epoch in range(CONFIG.EPOCHS):\n",
    "    model.train()\n",
    "    batch_loss = []\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = (X_batch - mu) / sigma\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs.squeeze(), y_batch) # squeeze pour ajuster les dimensions\n",
    "        \n",
    "        # Backward pass et optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss.append(loss.item())\n",
    "    \n",
    "    train_epoch_loss = np.mean(batch_loss)\n",
    "    \n",
    "    # Évaluation (Validation)\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in test_loader:\n",
    "            X_val = (X_val - mu) / sigma\n",
    "            outputs = model(X_val)\n",
    "            v_loss = criterion(outputs.squeeze(), y_val)\n",
    "            val_loss.append(v_loss.item())\n",
    "            \n",
    "    test_epoch_loss = np.mean(val_loss)\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{CONFIG.EPOCHS}], Train Loss: {train_epoch_loss:.4f}, Test Loss: {test_epoch_loss:.4f}\")\n",
    "    \n",
    "print(\"Entraînement terminé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3dc8904b-2f85-4655-8bd5-10144e75e60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.689896\n",
      "MSE: 0.003346\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Format specifier missing precision",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mR2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.06f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.06f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMAE: \u001b[39m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmae\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[33;43m.O9f\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m display_result_season(true, predict, index)\n",
      "\u001b[31mValueError\u001b[39m: Format specifier missing precision"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predict = []\n",
    "    true = []\n",
    "    for X, y in test_loader :\n",
    "        X = (X-mu)/sigma\n",
    "        y_hat = model(X)\n",
    "        predict.extend(y_hat.cpu())\n",
    "        true.extend(y.cpu())\n",
    "    index = X1.index[len(X1)-365:]\n",
    "    r2 = r2_score(true, predict)\n",
    "    mse = mean_squared_error(true, predict)\n",
    "    mae = mean_absolute_error(true, predict)\n",
    "    print(f\"R2: {r2:.06f}\")\n",
    "    print(f\"MSE: {mse:.06f}\")\n",
    "    print(f\"MAE: {mae:.O9f}\")\n",
    "    display_result_season(true, predict, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b25baa-0e2e-40f3-b55f-bd4d52f9aa12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
